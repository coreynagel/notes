0:00:00.000,0:00:00.340

0:00:00.340,0:00:02.790
PROFESSOR: So we had depth-first search,
we had breadth-first search.

0:00:02.790,0:00:05.600
They operate in very different ways, but
none of them solve the problem of

0:00:05.600,0:00:09.340
what happens if the arcs in my
graph have different weights.

0:00:09.340,0:00:11.590
But actually, we have all the
machinery that we need.

0:00:11.590,0:00:14.950
So breadth-first search will, in a graph
like this, it's that same graph,

0:00:14.950,0:00:17.830
if there are weights on these, then
breadth-first search will find the

0:00:17.830,0:00:20.330
shortest path in terms of
the number of actions.

0:00:20.330,0:00:26.410
So for example, it's going to find this
path, which is expensive because

0:00:26.410,0:00:30.150
that short single arc in
fact, weighs nine.

0:00:30.150,0:00:33.460
OK, the shortest path might be something
that requires a little bit

0:00:33.460,0:00:37.030
more in terms of number of steps,
but less in terms of cost.

0:00:37.030,0:00:40.560
So let's figure out what we can do with
breadth-first search in order to

0:00:40.560,0:00:44.370
make it sensitive to the costs and do
the right thing in terms of returning

0:00:44.370,0:00:46.490
the cheapest rather than the
shallowest solution.

0:00:46.490,0:00:47.740

0:00:47.000,0:00:48.410
PROFESSOR: And the solution is
going to be something called

0:00:48.410,0:00:49.990
uniform cost search.

0:00:49.990,0:00:52.130
It's going to be more or less just
like breadth-first search.

0:00:52.130,0:00:54.110
You start at the top and
you work your way down.

0:00:54.110,0:00:58.380
The difference is rather than going
evenly across the layers, prioritizing

0:00:58.380,0:01:01.480
them by their depth, instead
we're going to prioritize

0:01:01.480,0:01:02.760
them by their cost.

0:01:02.760,0:01:06.230
So that cheap things get done first,
even if they are multiple

0:01:06.230,0:01:08.540
steps into the tree.

0:01:08.540,0:01:10.570
So let's see how it works here.

0:01:10.570,0:01:14.600
So the strategy is going to be
expand not a shallowest node,

0:01:14.600,0:01:15.920
but a cheapest node.

0:01:15.920,0:01:19.840
That means we need to keep track of
for every node that we put on the

0:01:19.840,0:01:22.090
fringe, we need to keep
track of its cost.

0:01:22.090,0:01:25.710
Now, its cost is the cumulative cost
all the way from the beginning.

0:01:25.710,0:01:28.800
So the beginning, the fringe
just contains the node s.

0:01:28.800,0:01:31.270
It has cost zero because we
haven't done anything.

0:01:31.270,0:01:34.250
And when we pop that off, we put
its successors onto the fringe.

0:01:34.250,0:01:39.010
So now the fringe contains d, e, and
p with their respective costs.

0:01:39.010,0:01:43.440
OK, I won't draw the fringe at all
times, but in this particular case, it

0:01:43.440,0:01:45.020
would actually look like s to d.

0:01:45.020,0:01:47.370
The costs here would be three.

0:01:47.370,0:01:50.090
S to e, the cost here would be nine.

0:01:50.090,0:01:53.830
And s to p, where the
cost would be one.

0:01:53.830,0:01:57.840
Now when we look at this fringe, the
thing we'll expand next is s to p

0:01:57.840,0:02:00.940
because it's cheapest, and
then we'll continue on.

0:02:00.940,0:02:02.990
So in this case we'll expand s to p.

0:02:02.990,0:02:04.700
Its child goes onto the fringe.

0:02:04.700,0:02:08.050
Its child in this case happens
to be expensive.

0:02:08.050,0:02:10.630
OK, what's the next cheapest
thing on the fringe?

0:02:10.630,0:02:12.960
It's d, so we expand that.

0:02:12.960,0:02:15.060
And now there are various successors
on the fringe.

0:02:15.060,0:02:19.410
The cheapest thing here, breadth-first
search would go for e up here.

0:02:19.410,0:02:20.650
It would go for the shallow one.

0:02:20.650,0:02:24.900
But the cheapest one is actually
over here. this path to b.

0:02:24.900,0:02:26.530
S to d to b.

0:02:26.530,0:02:28.080
And so we'll pop that.

0:02:28.080,0:02:31.280
And you can see that we are kind of
working our way down, but we're always

0:02:31.280,0:02:32.610
doing the cheapest thing next.

0:02:32.610,0:02:36.680
So next we pop off the
cost five path to e.

0:02:36.680,0:02:37.910
What's next?

0:02:37.910,0:02:39.700
The path to a.

0:02:39.700,0:02:45.430
OK, that has no children, so the next
thing is the cost seven path to r.

0:02:45.430,0:02:47.610
And then the path to f.

0:02:47.610,0:02:49.020
Now, here's an interesting thing.

0:02:49.020,0:02:52.790
We found the path to g, but we
don't declare victory yet.

0:02:52.790,0:02:54.910
And here it's critical that we don't.

0:02:54.910,0:02:58.730
So on the fringe is a bunch of
paths, including one to g.

0:02:58.730,0:03:02.070
We don't stop, and in particular we
don't even process the path to g

0:03:02.070,0:03:03.550
because it's not the cheapest.

0:03:03.550,0:03:04.930
Instead, what do we do?

0:03:04.930,0:03:09.120
We finally make our way back up here
to that shallow path to e.

0:03:09.120,0:03:10.610
We process that.

0:03:10.610,0:03:15.300
Now we've processed every path
in the tree up to cost nine.

0:03:15.300,0:03:16.560
What's next?

0:03:16.560,0:03:17.950
Next is the goal path.

0:03:17.950,0:03:18.760
We return it.

0:03:18.760,0:03:20.000
We declare victory.

0:03:20.000,0:03:23.090
And it actually turns out
that this process will

0:03:23.090,0:03:26.440
guarantee us the cheapest.

0:03:26.440,0:03:28.010
So I said it was like breadth-first
search.

0:03:28.010,0:03:29.130
What does that mean?

0:03:29.130,0:03:33.330
Well, you do all the kind of cost one
things, then the cost two things, then

0:03:33.330,0:03:34.310
the cost three things.

0:03:34.310,0:03:37.820
Breath-first search did the depth one
things, then the depth two things,

0:03:37.820,0:03:38.890
then the depth three things.

0:03:38.890,0:03:41.460
So the difference is although you're
moving from the top to the bottom,

0:03:41.460,0:03:44.590
you're doing it in this ragged way
that follows the cost contours.

0:03:44.590,0:03:48.490
At any given time, you will
have expanded all paths up

0:03:48.490,0:03:49.860
to a certain cost.

0:03:49.860,0:03:52.710
And that's going to trace some jagged
thing through the tree depending on

0:03:52.710,0:03:55.090
how uneven the costs are
in your search problem.

0:03:56.870,0:03:58.680
What are the properties
of this search?

0:03:58.680,0:04:01.000
Well, what nodes get expanded?

0:04:01.000,0:04:02.230
We already know.

0:04:02.230,0:04:04.530
First, we're going to expand everything
where the cost is, say,

0:04:04.530,0:04:06.460
less than or equal to 1.

0:04:06.460,0:04:10.040
Then, eventually we'll expand everything
less than or equal to 2.

0:04:10.040,0:04:13.230
Eventually, we'll expand everything with
costs less than or equal to 3.

0:04:13.230,0:04:14.910
And so what do we expand?

0:04:14.910,0:04:18.970
All nodes with cost less than the
cost of the cheapest solution.

0:04:18.970,0:04:20.560
OK.

0:04:20.560,0:04:20.840
All right.

0:04:20.840,0:04:21.900
Now we need some notation.

0:04:21.900,0:04:23.430
This is a little bit heavy handed.

0:04:23.430,0:04:25.580
If the solution costs C*--

0:04:25.580,0:04:29.890
so that's the cost of this thing
here, this thing costs C*--

0:04:29.890,0:04:32.800
all right, how deeply
could we have gone?

0:04:32.800,0:04:37.280
Well, it depends how far down in terms
of steps we could go because that's

0:04:37.280,0:04:40.260
going to tell us the branching
factor to what.

0:04:40.260,0:04:44.260
Well, if we can bound to the cost of an
individual action, so each action

0:04:44.260,0:04:50.620
cost at least epsilon, say, 0.1, then we
can look at C* divided by epsilon.

0:04:50.620,0:04:55.800
That's essentially how deep the cheapest
solution could be, right?

0:04:55.800,0:04:57.760
And in the worst case, we're going
to do everything in the

0:04:57.760,0:04:59.220
graph up to that step.

0:04:59.220,0:05:02.400
OK, so we could say, in the worst
case, this'll take time.

0:05:02.400,0:05:03.830
It's still exponential in b.

0:05:03.830,0:05:07.580
It's now b to this effective depth,
which is the cost of the solution--

0:05:07.580,0:05:09.790
so the more expensive the solution
the deeper you go--

0:05:09.790,0:05:13.040
and divided by the cost
of the cheapest arc.

0:05:13.040,0:05:15.450
So if the arcs are really cheap, you
might have to go really deep to get an

0:05:15.450,0:05:17.500
expensive solution.

0:05:17.500,0:05:22.300
OK, so it's kind of like breadth for
search, but that depth is harder to

0:05:22.300,0:05:23.450
think about.

0:05:23.450,0:05:25.740
How much space does the fringe take?

0:05:25.740,0:05:29.560
Well, just like depth first search, the
fringe is kind of the periphery,

0:05:29.560,0:05:31.660
and that means it's basically
the same cost.

0:05:31.660,0:05:34.080
It's still exponential.

0:05:34.080,0:05:36.420
Is this thing complete?

0:05:36.420,0:05:39.500
Basically like breadth-first search
again, assuming that the best solution

0:05:39.500,0:05:43.260
has a finite cost and the minimum arc
cost is positive, yes, this is

0:05:43.260,0:05:46.060
complete as well.

0:05:46.060,0:05:47.150
Now, for the kicker.

0:05:47.150,0:05:49.570
Is it optimal?

0:05:49.570,0:05:53.090
Well, I will state, but not
prove, that it's optimal.

0:05:53.090,0:05:55.620
I'll prove it next lecture, because
it'll be a special case of the A*

0:05:55.620,0:05:56.450
search algorithm.

0:05:56.450,0:05:58.980
So yes, this is an optimal method.

0:05:58.980,0:06:01.930
It will return not the shallowest
solution like breadth-first search,

0:06:01.930,0:06:05.360
but the cheapest according
to the weights.

0:06:05.360,0:06:06.410
What's it going to do?

0:06:06.410,0:06:11.210
Well remember, it explores increasing
cost contours, and the good of that is

0:06:11.210,0:06:13.260
it's complete and optimal.

0:06:13.260,0:06:17.190
The bad, which we're going to have to
fix next lecture, is that it explores

0:06:17.190,0:06:18.440
in every direction.

0:06:18.440,0:06:21.230
I'll show you that in the demo
and we'll fix it next time.

0:06:21.230,0:06:24.590
What that means is, from the start, you
consider all the things that you

0:06:24.590,0:06:28.400
could do that are cheap, whether they're
making progress towards the

0:06:28.400,0:06:29.710
goal or not.

0:06:29.710,0:06:29.870
Right.

0:06:29.870,0:06:32.520
So I want to get to that door, and
so I think of everything I

0:06:32.520,0:06:36.180
could do with 50 steps.

0:06:36.180,0:06:37.580
Probably that's a waste.

0:06:37.580,0:06:39.990
There's a lot of things you can do
with 50 steps that don't get you

0:06:39.990,0:06:42.570
anywhere to your door,
and we'll fix that.

